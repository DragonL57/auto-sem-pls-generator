# M√°y T·∫°o D·ªØ Li·ªáu T·ªïng H·ª£p SEM/PLS v·ªõi Bayesian Optimization

C√¥ng c·ª• to√†n di·ªán t·∫°o d·ªØ li·ªáu t·ªïng h·ª£p ch·∫•t l∆∞·ª£ng cao cho nghi√™n c·ª©u Structural Equation Modeling (SEM) v√† Partial Least Squares (PLS), s·ª≠ d·ª•ng thu·∫≠t to√°n Bayesian Optimization hi·ªán ƒë·∫°i ƒë·ªÉ t·ª± ƒë·ªông t·ªëi ∆∞u h√≥a c√°c tham s·ªë m√¥ h√¨nh.

## üåü T√≠nh NƒÉng N·ªïi B·∫≠t

### ü§ñ T·ªëi ∆Øu H√≥a Th√¥ng Minh
- **Bayesian Optimization** t·ª± ƒë·ªông t√¨m ki·∫øm tham s·ªë t·ªëi ∆∞u
- **Expected Improvement (EI)** acquisition function hi·ªáu qu·∫£
- **Early stopping** th√¥ng minh ƒë·ªÉ ti·∫øt ki·ªám th·ªùi gian
- **Adaptive search space** t·ª± ƒëi·ªÅu ch·ªânh kh√¥ng gian t√¨m ki·∫øm

### üìä T·∫°o D·ªØ Li·ªáu Ch·∫•t L∆∞·ª£ng Cao
- **Likert-scale data** v·ªõi ph√¢n ph·ªëi chu·∫©n x√°c
- **Latent factor structure** tu√¢n th·ªß ma tr·∫≠n t∆∞∆°ng quan m·ª•c ti√™u
- **Controlled error variance** v·ªõi ƒë·ªô l·ªói t√πy ch·ªânh
- **Realistic factor loadings** m√¥ ph·ªèng d·ªØ li·ªáu th·ª±c

### üîç X√°c Th·ª±c Th·ªëng K√™ To√†n Di·ªán
- **Cronbach's Alpha** ki·ªÉm tra ƒë·ªô tin c·∫≠y
- **Exploratory Factor Analysis (EFA)** v·ªõi promax rotation
- **KMO-Bartlett tests** ki·ªÉm tra t√≠nh ph√π h·ª£p ph√¢n t√≠ch nh√¢n t·ªë
- **Regression analysis** v·ªõi ƒë·∫ßy ƒë·ªß th·ªëng k√™
- **Heywood cases detection** v√† t·ª± ƒë·ªông s·ª≠a ch·ªØa

### üìà Xu·∫•t K·∫øt Qu·∫£ Chuy√™n Nghi·ªáp
- **Multi-sheet Excel** v·ªõi d·ªØ li·ªáu v√† ph√¢n t√≠ch
- **Real-time console output** hi·ªÉn th·ªã ti·∫øn tr√¨nh
- **Comprehensive logging** cho debugging v√† ki·ªÉm tra
- **Automatic model validation** v·ªõi chi ti·∫øt t·ª´ng b∆∞·ªõc

## üìã Y√™u C·∫ßu H·ªá Th·ªëng

### Ph·∫ßn C·ª©ng T·ªëi Thi·ªÉu
- **CPU**: 4 cores tr·ªü l√™n (khuy·∫øn ngh·ªã 8+ cores)
- **RAM**: 8GB RAM (khuy·∫øn ngh·ªã 16GB+)
- **Storage**: 1GB kh√¥ng gian tr·ªëng

### Ph·∫ßn M·ªÅm
- **Python**: 3.8 tr·ªü l√™n (khuy·∫øn ngh·ªã 3.9+)
- **OS**: Windows 10+, macOS 10.15+, Linux Ubuntu 18.04+

### Dependencies
```
numpy>=1.21.0
pandas>=1.3.0
scipy>=1.7.0
scikit-learn>=1.0.0
statsmodels>=0.12.0
factor_analyzer>=0.4.0
openpyxl>=3.0.0
scikit-optimize>=0.9.0
```

## üöÄ H∆∞·ªõng D·∫´n C√†i ƒê·∫∑t Chi Ti·∫øt

### 1. Clone Repository
```bash
git clone https://github.com/DragonL57/auto-sem-pls-generator.git
cd auto-sem-pls-generator
```

### 2. T·∫°o M√¥i Tr∆∞·ªùng ·∫¢o (B·∫Øt Bu·ªôc)
```bash
# T·∫°o m√¥i tr∆∞·ªùng ·∫£o
python -m venv venv

# K√≠ch ho·∫°t m√¥i tr∆∞·ªùng
# Windows
venv\Scripts\activate
# Linux/Mac
source venv/bin/activate

# C·∫≠p nh·∫≠t pip
pip install --upgrade pip
```

### 3. C√†i ƒê·∫∑t Dependencies
```bash
# C√†i ƒë·∫∑t t·ª´ requirements.txt
pip install -r requirements.txt

# X√°c nh·∫≠n c√†i ƒë·∫∑t th√†nh c√¥ng
python -c "import numpy, pandas, sklearn, statsmodels; print('All dependencies installed successfully')"
```

### 4. C·∫•u H√¨nh VSCode (Khuy·∫øn Ngh·ªã)
```json
// .vscode/settings.json
{
    "python.defaultInterpreterPath": "./venv/Scripts/python",
    "python.linting.enabled": true,
    "python.formatting.provider": "black"
}
```

## üîß C·∫•u H√¨nh M√¥ H√¨nh Chi Ti·∫øt

### 1. C·∫•u H√¨nh Ma Tr·∫≠n T∆∞∆°ng Quan Ti·ªÅm ·∫®n

File `config.py` cho ph√©p b·∫°n ki·ªÉm so√°t m·ªëi quan h·ªá gi·ªØa c√°c nh√¢n t·ªë ti·ªÅm ·∫©n:

```python
# ================== MA TR·∫¨N T∆Ø∆†NG QUAN TI·ªÄM ·∫®N ==================
latent_correlation_matrix = None  # T·ª± ƒë·ªông t·ªëi ∆∞u h√≥a
# HO·∫∂C ƒë·∫∑t ma tr·∫≠n c·ª• th·ªÉ:
latent_correlation_matrix = [
    [1.000, 0.300, 0.250, 0.400, 0.350, 0.200, 0.150, 0.100],
    [0.300, 1.000, 0.350, 0.300, 0.250, 0.400, 0.300, 0.200],
    [0.250, 0.350, 1.000, 0.450, 0.300, 0.250, 0.350, 0.250],
    [0.400, 0.300, 0.450, 1.000, 0.500, 0.300, 0.200, 0.150],
    [0.350, 0.250, 0.300, 0.500, 1.000, 0.350, 0.250, 0.200],
    [0.200, 0.400, 0.250, 0.300, 0.350, 1.000, 0.600, 0.400],
    [0.150, 0.300, 0.350, 0.200, 0.250, 0.600, 1.000, 0.500],
    [0.100, 0.200, 0.250, 0.150, 0.200, 0.400, 0.500, 1.000]
]
```

**L∆∞u √Ω quan tr·ªçng:**
- Ma tr·∫≠n ph·∫£i vu√¥ng v√† ƒë·ªëi x·ª©ng
- ƒê∆∞·ªùng ch√©o lu√¥n = 1.0 (t·ª± t∆∞∆°ng quan)
- Gi√° tr·ªã ngo√†i ƒë∆∞·ªùng ch√©o: -1 ƒë·∫øn 1 (th∆∞·ªùng 0.1-0.8)
- Th·ª© t·ª± nh√¢n t·ªë ph·∫£i kh·ªõp v·ªõi `factors_config`

### 2. C·∫•u H√¨nh Nh√¢n T·ªë v√† Bi·∫øn Quan S√°t

ƒê·ªãnh nghƒ©a c√°c nh√¢n t·ªë ti·ªÅm ·∫©n v√† bi·∫øn quan s√°t t∆∞∆°ng ·ª©ng:

```python
factors_config = {
    "SI":  {"original_items": ["SI1", "SI2", "SI3"]},                    # ·∫¢nh h∆∞·ªüng x√£ h·ªôi
    "GOV": {"original_items": ["GOV1", "GOV2", "GOV3", "GOV4", "GOV5", "GOV6"]},  # Ch√≠nh ph·ªß
    "LCI": {"original_items": ["LCI1", "LCI2", "LCI3"]},                  # C∆° s·ªü h·∫° t·∫ßng s·∫°c
    "PU":  {"original_items": ["PU1", "PU2", "PU3"]},                     # Nh·∫≠n th·ª©c h·ªØu √≠ch
    "PE":  {"original_items": ["PE1", "PE2", "PE3"]},                     # Nh·∫≠n th·ª©c d·ªÖ s·ª≠ d·ª•ng
    "EA":  {"original_items": ["EA1", "EA2", "EA3", "EA4", "EA5"]},        # M√¥i tr∆∞·ªùng
    "PN":  {"original_items": ["PN1", "PN2", "PN3", "PN4"]},              # Chu·∫©n m·ª±c c√° nh√¢n
    "BI":  {"original_items": ["BI1", "BI2", "BI3", "BI4"]}               # √ù ƒë·ªãnh s·ª≠ d·ª•ng xe ƒëi·ªán
}
```

### 3. C·∫•u H√¨nh M√¥ H√¨nh H·ªìi Quy

X√°c ƒë·ªãnh c√°c m·ªëi quan h·ªá nh√¢n qu·∫£ v√† th·ª© t·ª± ·∫£nh h∆∞·ªüng mong ƒë·ª£i:

```python
regression_models = [
    # M√¥ h√¨nh 1: M√¥i tr∆∞·ªùng t√°c ƒë·ªông ƒë·∫øn Chu·∫©n m·ª±c c√° nh√¢n
    {"dependent": "PN_composite", 
     "independent": ["EA_composite"], 
     "order": ["EA_composite"]},
    
    # M√¥ h√¨nh 2: C√°c y·∫øu t·ªë t√°c ƒë·ªông ƒë·∫øn √ù ƒë·ªãnh s·ª≠ d·ª•ng xe ƒëi·ªán
    # Th·ª© t·ª±: PE > PU > GOV > LCI > SI > PN (t·ª´ m·∫°nh nh·∫•t ƒë·∫øn y·∫øu nh·∫•t)
    {"dependent": "BI_composite",
     "independent": ["PE_composite", "PU_composite", "GOV_composite", "LCI_composite", "SI_composite", "PN_composite"],
     "order": ["PE_composite", "PU_composite", "GOV_composite", "LCI_composite", "SI_composite", "PN_composite"]}
]
```

**Gi·∫£i th√≠ch c·∫•u tr√∫c:**
- `dependent`: Bi·∫øn k·∫øt qu·∫£ (ph·∫£i c√≥ `_composite` suffix)
- `independent`: Danh s√°ch c√°c bi·∫øn ƒë·ªôc l·∫≠p ·∫£nh h∆∞·ªüng
- `order`: Th·ª© t·ª± mong ƒë·ª£i ƒë·ªô m·∫°nh ·∫£nh h∆∞·ªüng (t·ª´ m·∫°nh ‚Üí y·∫øu)

### 4. C·∫•u H√¨nh Tham S·ªë Bayesian Optimization

```python
# ================== THAM S·ªê BAYESIAN OPTIMIZATION ==================
num_observations = 367                    # S·ªë m·∫´u c·∫ßn t·∫°o

# Th√¥ng s·ªë t·ªëi ∆∞u h√≥a
bo_n_calls = 120                         # S·ªë l·∫ßn ƒë√°nh gi√° t·ªëi ƒëa
bo_n_initial_points = 15                 # S·ªë ƒëi·ªÉm kh√°m ph√° ban ƒë·∫ßu
bo_acq_func = 'EI'                       # Acquisition function
bo_n_jobs = -1                          # S·ªë processes (-1 = t·∫•t c·∫£ cores)
bo_early_stopping = True                 # B·∫≠t early stopping
bo_patience = 12                        # S·ªë iteration ch·ªù tr∆∞·ªõc khi d·ª´ng

# Kh√¥ng gian t√¨m ki·∫øm
bo_latent_cor_min = 0.01                 # T∆∞∆°ng quan ti·ªÅm ·∫©n t·ªëi thi·ªÉu
bo_latent_cor_max = 0.5                  # T∆∞∆°ng quan ti·ªÅm ·∫©n t·ªëi ƒëa
bo_error_strength_min = 0.25             # ƒê·ªô l·ªói t·ªëi thi·ªÉu
bo_error_strength_max = 0.45              # ƒê·ªô l·ªói t·ªëi ƒëa
bo_loading_strength_min = 0.55            # T·∫£i nh√¢n t·ªë t·ªëi thi·ªÉu
bo_loading_strength_max = 0.75            # T·∫£i nh√¢n t·ªë t·ªëi ƒëa
```

## üèÉ H∆∞·ªõng D·∫´n S·ª≠ D·ª•ng

### 1. Ch·∫°y Ch∆∞∆°ng Tr√¨nh C∆° B·∫£n
```bash
# K√≠ch ho·∫°t m√¥i tr∆∞·ªùng ·∫£o
venv\Scripts\activate

# Ch·∫°y ch∆∞∆°ng tr√¨nh
python main.py
```

### 2. T√πy Ch·ªçn S·ªë Processes
```bash
# S·ª≠ d·ª•ng 4 processes (khuy·∫øn ngh·ªã cho CPU 8 cores)
python main.py --processes 4

# S·ª≠ d·ª•ng 1 process (n·∫øu g·∫∑p l·ªói multiprocessing)
python main.py --processes 1
```

### 3. Gi√°m S√°t Ti·∫øn Tr√¨nh
Ch∆∞∆°ng tr√¨nh s·∫Ω hi·ªÉn th·ªã ti·∫øn tr√¨nh real-time:
```
==================================================
B·∫ÆT ƒê·∫¶U QU√Å TR√åNH T·ªêI ∆ØU H√ìA (BAYESIAN OPTIMIZATION)
S·ªë evaluations: 120
S·ªë ƒëi·ªÉm kh·ªüi t·∫°o: 15
Acquisition function: EI
==================================================
Evaluation 5/120: Best score = 1850.42, Current = 1420.15
Evaluation 10/120: Best score = 1920.78, Current = 1680.45
...
```

## üìä K·∫øt Qu·∫£ ƒê·∫ßu Ra Chi Ti·∫øt

### 1. File Excel (`output/output.xlsx`)

**Sheet 1: Generated Data**
- D·ªØ li·ªáu t·ªïng h·ª£p th√¥ cho t·∫•t c·∫£ bi·∫øn quan s√°t
- Composite scores cho t·ª´ng nh√¢n t·ªë
- Interaction variables (n·∫øu c√≥)

**Sheet 2: Statistical Analysis**
- Th·ªëng k√™ m√¥ t·∫£ (mean, SD, min, max, skewness, kurtosis)
- Ma tr·∫≠n t∆∞∆°ng quan Pearson
- Histogram v√† Q-Q plots

**Sheet 3: Factor Analysis**
- K·∫øt qu·∫£ EFA v·ªõi promax rotation
- Factor loadings matrix
- Communalities v√† uniqueness
- Factor correlation matrix

**Sheet 4: Regression Results**
- Regression coefficients v√† standard errors
- t-values v√† p-values
- R-squared, Adjusted R-squared
- VIF (Variance Inflation Factors)
- Residual analysis

**Sheet 5: Diagnostics**
- Cronbach's Alpha cho t·ª´ng nh√¢n t·ªë
- KMO v√† Bartlett's test results
- Reliability statistics
- Validity measures

### 2. Console Output Real-time
```
==================================================
QU√Å TR√åNH T·ªêI ∆ØU H√ìA (BAYESIAN OPTIMIZATION) HO√ÄN T·∫§T
T·ªïng th·ªùi gian ch·∫°y: 45.32 gi√¢y
S·ªë evaluations th·ª±c t·∫ø: 98
==================================================
ƒêi·ªÉm s·ªë t·ªët nh·∫•t t√¨m ƒë∆∞·ª£c: 2150.75
L√Ω do: Valid model with good fit indices

B·ªô tham s·ªë t·ªët nh·∫•t:
  ƒê·ªô m·∫°nh t·∫£i nh√¢n t·ªë (Loading Strength): 0.685
  ƒê·ªô m·∫°nh sai s·ªë (Error Strength): 0.342
  C√°c gi√° tr·ªã t∆∞∆°ng quan ti·ªÅm ·∫©n: [0.245, 0.189, 0.321, ...]
```

### 3. Log File (`output/terminal.log`)
- Ghi l·∫°i to√†n b·ªô output console
- D√πng cho debugging v√† ki·ªÉm tra
- UTF-8 encoding h·ªó tr·ª£ ti·∫øng Vi·ªát

## üß† Bayesian Optimization Chi Ti·∫øt

### Thu·∫≠t To to√°n T·ªëi ∆Øu H√≥a
H·ªá th·ªëng s·ª≠ d·ª•ng **Gaussian Process-based Bayesian Optimization** v·ªõi:

- **Surrogate Model**: Gaussian Process Regression v·ªõi RBF kernel
- **Acquisition Function**: Expected Improvement (EI)
- **Search Strategy**: Tree-structured Parzen Estimator (TPE)
- **Convergence Criteria**: Early stopping v·ªõi patience

### Kh√¥ng Gian T√¨m Ki·∫øm
| Parameter | Min | Max | M·ª•c ƒê√≠ch |
|-----------|-----|-----|----------|
| Latent Correlations | 0.01 | 0.5 | Tr√°nh Heywood cases |
| Error Strength | 0.25 | 0.45 | TƒÉng reliability |
| Loading Strength | 0.55 | 0.75 | TƒÉng convergent validity |

### Fitness Function
ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng m√¥ h√¨nh d·ª±a tr√™n:

1. **Reliability Scores** (40%)
   - Cronbach's Alpha ‚â• 0.7
   - Composite reliability ‚â• 0.7

2. **Validity Scores** (30%)
   - Convergent validity (AVE ‚â• 0.5)
   - Discriminant validity
   - Cross-loadings < 0.4

3. **Model Fit** (20%)
   - CFI ‚â• 0.90
   - TLI ‚â• 0.90
   - RMSEA ‚â§ 0.08

4. **Regression Quality** (10%)
   - R-squared ‚â• 0.3
   - Significant coefficients (p < 0.05)
   - Expected beta coefficient order

## üìà X√°c Th·ª±c Th·ªëng K√™ To√†n Di·ªán

### 1. Reliability Analysis
- **Cronbach's Alpha**: ƒêo l∆∞·ªùng t√≠nh nh·∫•t qu√°n n·ªôi b·ªô
- **Composite Reliability**: ƒêo l∆∞·ªùng ƒë·ªô tin c·∫≠y t·ªïng h·ª£p
- **Average Variance Extracted (AVE)**: ƒêo l∆∞·ªùng convergent validity

### 2. Validity Analysis
- **Exploratory Factor Analysis (EFA)**: Kh√°m ph√° c·∫•u tr√∫c nh√¢n t·ªë
- **Confirmatory Factor Analysis (CFA)**: X√°c nh·∫≠n c·∫•u tr√∫c gi·∫£ thuy·∫øt
- **Discriminant Validity**: Ph√¢n bi·ªát gi·ªØa c√°c nh√¢n t·ªë
- **Convergent Validity**: T√≠nh h·ªôi t·ª• c·ªßa c√°c bi·∫øn

### 3. Regression Analysis
- **Multiple Linear Regression**: Ph√¢n t√≠ch m·ªëi quan h·ªá nh√¢n qu·∫£
- **Hierarchical Regression**: Ph√¢n t√≠ch theo c·∫•p b·∫≠c
- **Moderation Analysis**: Ph√¢n t√≠ch hi·ªáu qu·∫£ ƒëi·ªÅu ti·∫øt

### 4. Advanced Diagnostics
- **Heywood Cases Detection**: Ph√°t hi·ªán v√† s·ª≠a l·ªói ma tr·∫≠n
- **Multicollinearity Check**: Ki·ªÉm tra ƒëa c·ªông tuy·∫øn
- **Normality Tests**: Ki·ªÉm tra ph√¢n ph·ªëi chu·∫©n
- **Outlier Detection**: Ph√°t hi·ªán gi√° tr·ªã ngo·∫°i lai

## üîç Kh·∫Øc Ph·ª•c S·ª± C·ªë Chi Ti·∫øt

### 1. L·ªói Multiprocessing
```
Error: Can't get local object 'function_name'
```
**Nguy√™n nh√¢n**: Python serialization issues with multiprocessing
**Gi·∫£i ph√°p**:
```bash
# S·ª≠ d·ª•ng single process
python main.py --processes 1

# Ho·∫∑c gi·∫£m s·ªë processes
python main.py --processes 2
```

### 2. Heywood Cases
```
Error: Heywood (Latent Diag > 1)
```
**Nguy√™n nh√¢n**: Correlation values qu√° cao t·∫°o ma tr·∫≠n kh√¥ng x√°c ƒë·ªãnh d∆∞∆°ng
**Gi·∫£i ph√°p**:
- Gi·∫£m `bo_latent_cor_max` (v√≠ d·ª•: 0.5 ‚Üí 0.4)
- TƒÉng s·ªë iterations (`bo_n_calls`)
- Ki·ªÉm tra l·∫°i factor structure

### 3. Convergence Issues
```
Error: No convergence in maximum iterations
```
**Gi·∫£i ph√°p**:
- TƒÉng `bo_n_initial_points` (v√≠ d·ª•: 15 ‚Üí 20)
- Thay ƒë·ªïi `bo_acq_func` ('EI' ‚Üí 'LCB')
- TƒÉng `bo_patience` (v√≠ d·ª•: 12 ‚Üí 15)

### 4. Low Fitness Scores
```
Best score: < 1000
```
**Gi·∫£i ph√°p**:
- M·ªü r·ªông search space bounds
- Ki·ªÉm tra l·∫°i model specification
- TƒÉng s·ªë observations
- ƒêi·ªÅu ch·ªânh regression model

### 5. Encoding Issues
```
UnicodeEncodeError: 'charmap' codec
```
**Gi·∫£i ph√°p**:
```bash
# S·ª≠ d·ª•ng terminal h·ªó tr·ª£ UTF-8
chcp 65001
python main.py
```

## üìù C·∫•u Tr√∫c File Chi Ti·∫øt

```
auto-sem-pls-generator/
‚îú‚îÄ‚îÄ main.py                    # Entry point ch√≠nh
‚îú‚îÄ‚îÄ config.py                 # C·∫•u h√¨nh to√†n b·ªô m√¥ h√¨nh
‚îú‚îÄ‚îÄ bayesian_optimizer.py     # Bayesian optimization engine
‚îú‚îÄ‚îÄ evaluation.py            # Fitness function v√† model evaluation
‚îú‚îÄ‚îÄ data_generation.py       # T·∫°o d·ªØ li·ªáu t·ªïng h·ª£p
‚îú‚îÄ‚îÄ diagnostics.py           # Statistical validation
‚îú‚îÄ‚îÄ utils.py                # Utility functions
‚îú‚îÄ‚îÄ metrics.py              # Statistical calculations
‚îú‚îÄ‚îÄ latent_utils.py         # Latent variable processing
‚îú‚îÄ‚îÄ requirements.txt         # Python dependencies
‚îú‚îÄ‚îÄ .vscode/
‚îÇ   ‚îî‚îÄ‚îÄ settings.json        # VSCode configuration
‚îú‚îÄ‚îÄ README.md               # Documentation
‚îú‚îÄ‚îÄ .gitignore              # Git ignore rules
‚îú‚îÄ‚îÄ venv/                   # Virtual environment
‚îî‚îÄ‚îÄ output/                 # Results directory
    ‚îú‚îÄ‚îÄ output.xlsx         # Excel results
    ‚îú‚îÄ‚îÄ terminal.log        # Execution log
    ‚îî‚îÄ‚îÄ temp/               # Temporary files
```

### M√¥ T·∫£ C√°c File Ch√≠nh

**main.py**: Entry point c·ªßa ch∆∞∆°ng tr√¨nh
- Kh·ªüi t·∫°o Bayesian Optimization
- Qu·∫£n l√Ω ti·∫øn tr√¨nh th·ª±c thi
- X·ª≠ l√Ω output v√† logging

**config.py**: File c·∫•u h√¨nh trung t√¢m
- ƒê·ªãnh nghƒ©a factor structure
- C·∫•u h√¨nh regression models
- Thi·∫øt l·∫≠p optimization parameters

**bayesian_optimizer.py**: Core optimization engine
- Gaussian Process implementation
- Acquisition function calculations
- Search space management

**evaluation.py**: Model evaluation system
- Fitness function implementation
- Statistical validation
- Penalty score calculations

## üéØ M√¥ H√¨nh Hi·ªán T·∫°i: √ù ƒê·ªãnh S·ª≠ D·ª•ng Xe ƒêi·ªán

### C√°c Nh√¢n T·ªë Nghi√™n C·ª©u
1. **SI** (Social Influence): ·∫¢nh h∆∞·ªüng x√£ h·ªôi (3 items)
2. **GOV** (Government): Ch√≠nh ph·ªß (6 items)
3. **LCI** (Charging Infrastructure): C∆° s·ªü h·∫° t·∫ßng s·∫°c (3 items)
4. **PU** (Perceived Usefulness): Nh·∫≠n th·ª©c h·ªØu √≠ch (3 items)
5. **PE** (Perceived Ease of Use): Nh·∫≠n th·ª©c d·ªÖ s·ª≠ d·ª•ng (3 items)
6. **EA** (Environmental Awareness): Nh·∫≠n th·ª©c m√¥i tr∆∞·ªùng (5 items)
7. **PN** (Personal Norms): Chu·∫©n m·ª±c c√° nh√¢n (4 items)
8. **BI** (Behavioral Intention): √ù ƒë·ªãnh s·ª≠ d·ª•ng xe ƒëi·ªán (4 items)

### M√¥ H√¨nh H·ªìi Quy
- **Model 1**: EA ‚Üí PN (M√¥i tr∆∞·ªùng ‚Üí Chu·∫©n m·ª±c c√° nh√¢n)
- **Model 2**: [PE, PU, GOV, LCI, SI, PN] ‚Üí BI (Th·ª© t·ª± strength: PE > PU > GOV > LCI > SI > PN)

### Th·ª© T·ª± ·∫¢nh H∆∞·ªüng Mong ƒê·ª£i
1. **EA ‚Üí PN** (M·∫°nh nh·∫•t)
2. **PE ‚Üí BI** (M·∫°nh th·ª© 2)
3. **PU ‚Üí BI** (M·∫°nh th·ª© 3)
4. **GOV ‚Üí BI** (M·∫°nh th·ª© 4)
5. **LCI ‚Üí BI** (M·∫°nh th·ª© 5)
6. **SI ‚Üí BI** (M·∫°nh th·ª© 6)
7. **PN ‚Üí BI** (Y·∫øu nh·∫•t)

## üöÄ T·ªëi ∆Øu H√≥a Hi·ªáu Su·∫•t

### T·ªëi ∆Øu Cho M√°y Nhi·ªÅu Cores
```bash
# CPU 16 cores ‚Üí s·ª≠ d·ª•ng 15 processes
python main.py --processes 15

# CPU 8 cores ‚Üí s·ª≠ d·ª•ng 7 processes
python main.py --processes 7

# CPU 4 cores ‚Üí s·ª≠ d·ª•ng 3 processes
python main.py --processes 3
```

### T·ªëi ∆Øu Th·ªùi Gian Ch·∫°y
- **Fast mode**: `bo_n_calls = 60`, `bo_n_initial_points = 10`
- **Normal mode**: `bo_n_calls = 120`, `bo_n_initial_points = 15`
- **Thorough mode**: `bo_n_calls = 200`, `bo_n_initial_points = 25`

### T·ªëi ∆Øu Ch·∫•t L∆∞·ª£ng
- **Quality mode**: Gi·∫£m search space, tƒÉng iterations
- **Exploration mode**: M·ªü r·ªông search space, tƒÉng initial points
- **Balanced mode**: C√¢n b·∫±ng gi·ªØa exploration v√† exploitation

## üìä Di·ªÖn Gi·∫£i K·∫øt Qu·∫£

### 1. ƒê·ªçc K·∫øt Qu·∫£ Regression
- **R-squared**: > 0.3 (acceptable), > 0.5 (good), > 0.7 (excellent)
- **Beta coefficients**: Gi√° tr·ªã d∆∞∆°ng/negative ph√π h·ª£p gi·∫£ thuy·∫øt
- **p-values**: < 0.05 (significant), < 0.01 (highly significant)
- **VIF**: < 5 (acceptable), < 3 (good)

### 2. ƒê√°nh Gi√° Model Fit
- **Cronbach's Alpha**: > 0.7 (acceptable), > 0.8 (good)
- **KMO**: > 0.6 (acceptable), > 0.8 (good)
- **Factor Loadings**: > 0.5 (acceptable), > 0.7 (good)
- **AVE**: > 0.5 (acceptable)

### 3. X√°c Th·ª±c Hypotheses
- **Hypothesis supported**: p < 0.05 v√† beta ƒë√∫ng d·∫•u
- **Hypothesis rejected**: p ‚â• 0.05 ho·∫∑c beta sai d·∫•u
- **Effect size**: Small (0.1), Medium (0.3), Large (0.5)

## ü§ù ƒê√≥ng G√≥p v√† Ph√°t Tri·ªÉn

### C√°ch ƒê√≥ng G√≥p
1. **Fork** repository
2. T·∫°o **feature branch**: `git checkout -b feature/amazing-feature`
3. **Commit changes**: `git commit -m 'Add amazing feature'`
4. **Push**: `git push origin feature/amazing-feature`
5. **Pull Request**: M·ªü PR tr√™n GitHub

### Quy Tr√¨nh Ph√°t Tri·ªÉn
- Tu√¢n th·ªß PEP 8 cho coding style
- Th√™m tests cho c√°c functions m·ªõi
- C·∫≠p nh·∫≠t documentation khi thay ƒë·ªïi
- Review code tr∆∞·ªõc khi merge

### Areas for Improvement
- Th√™m acquisition functions m·ªõi
- H·ªó tr·ª£ c√°c lo·∫°i d·ªØ li·ªáu kh√°c (ordinal, nominal)
- Th√™m visualization tools
- TƒÉng t·ªëc ƒë·ªô convergence

## üìÑ Gi·∫•y Ph√©p v√† S·ª≠ D·ª•ng

### Gi·∫•y Ph√©p
This project is licensed under the MIT License - see the LICENSE file for details.

### M·ª•c ƒê√≠ch S·ª≠ D·ª•ng
- ‚úÖ Academic research
- ‚úÖ Educational purposes
- ‚úÖ Methodological development
- ‚ùå Commercial use without permission
- ‚ùå Medical/clinical applications

### Citation
N·∫øu s·ª≠ d·ª•ng c√¥ng c·ª• n√†y trong nghi√™n c·ª©u, vui l√≤ng citation:
```
Auto SEM/PLS Data Generator (Version 1.0)
https://github.com/DragonL57/auto-sem-pls-generator
```

## üîó Li√™n K·∫øt H·ªØu √çch

### Documentation
- **Official Documentation**: [Link]
- **API Reference**: [Link]
- **Tutorial Videos**: [Link]

### Community
- **GitHub Issues**: https://github.com/DragonL57/auto-sem-pls-generator/issues
- **Discussions**: https://github.com/DragonL57/auto-sem-pls-generator/discussions
- **Email Support**: [Contact]

### Related Tools
- **R semTools Package**: https://cran.r-project.org/package=semTools
- **Python semopy Package**: https://github.com/georgy-seledtskov/semopy
- **Lavaan (R)**: https://lavaan.ugent.be/

---

**Note**: C√¥ng c·ª• n√†y ƒë∆∞·ª£c ph√°t tri·ªÉn cho m·ª•c ƒë√≠ch h·ªçc thu·∫≠t v√† nghi√™n c·ª©u. Vui l√≤ng tham kh·∫£o t√†i li·ªáu SEM/PLS ph√π h·ª£p khi s·ª≠ d·ª•ng k·∫øt qu·∫£ trong c√°c c√¥ng b·ªë khoa h·ªçc.

**Last Updated**: September 2025
**Version**: 1.0.0
**Maintainer**: DragonL57